{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fH_jEjT_MZo"
      },
      "outputs": [],
      "source": [
        "from  google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59bgrtJ0_a_H",
        "outputId": "01bc3b5f-3c95-4a2b-c0a5-b8ac197497f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzEvYeu7R-AY",
        "outputId": "3c52b048-770f-4169-ef4c-70a3d97095ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0.\n",
            "  Downloading torchtext-0.10.0-cp38-cp38-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0.) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0.) (4.64.1)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.10.0.) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0->torchtext==0.10.0.) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0.) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0.) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0.) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.10.0.) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.0\n",
            "    Uninstalling torchtext-0.14.0:\n",
            "      Successfully uninstalled torchtext-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy import data , datasets\n",
        "import random\n",
        "import spacy"
      ],
      "metadata": {
        "id": "drXKYb-__jY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_folder = '/content/drive/MyDrive/data'\n",
        "destination_folder ='/content/drive/MyDrive/data_save'"
      ],
      "metadata": {
        "id": "-P07NIFVA8Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparing data , we'll set the seed, define the Fields and get the train/valid/test splits"
      ],
      "metadata": {
        "id": "Ai_E9ap5G0NR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed =1234\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "Text = data.Field(tokenize = 'spacy',tokenizer_language = 'en_core_web_sm',include_lengths= True)\n",
        "Label = data.LabelField(dtype=torch.float)"
      ],
      "metadata": {
        "id": "Z9YILTelBQb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define the fields"
      ],
      "metadata": {
        "id": "6Q4UP5KKHSwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [('text', Text),  ('Sentiment', Label)]"
      ],
      "metadata": {
        "id": "5KEWeXT4B9Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pass the location of the train/valid/test data"
      ],
      "metadata": {
        "id": "Qj-jiAQrIFZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                                        path = source_folder ,\n",
        "                                        train = 'train.csv',\n",
        "                                        validation = 'valid.csv',\n",
        "                                        test = 'test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields,\n",
        "                                        skip_header = True\n",
        ")"
      ],
      "metadata": {
        "id": "rYWwESJHBoAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3UYVWCvCqNB",
        "outputId": "0b7fa09c-234e-45d1-fc4b-3bbcf5a1a16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['man', 'need', 'finish', 'working', 'play', 'persona'], 'Sentiment': '0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "downloading the vectors and associating them with the correct words in our vocabulary and we'll be using the \"glove.6B.100d\" vectors\" glove is the algorithm used to calculate the vectors and by setting unk_init to torch.Tensor.normal_. This will now initialize those words via a Gaussian distribution."
      ],
      "metadata": {
        "id": "xV_GECMoIVva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import Vectors\n",
        "max_size = 25000\n",
        "Text.build_vocab(train_data,max_size=max_size,vectors = \"glove.6B.100d\",unk_init=torch.Tensor.normal_)\n",
        "Label.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "SBMaDj-3C6Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fd7005-93f2-4d04-8198-4f4e9f8c5d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:12<00:00, 32776.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "placing the tensors on the GPU if one is available"
      ],
      "metadata": {
        "id": "LeQULgWKIa_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_size = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "cJKag0FoDqz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the iterators"
      ],
      "metadata": {
        "id": "HmqQQk0ZI1-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator,valid_iterator,test_iterator = data.BucketIterator.splits((train_data,valid_data,test_data),\n",
        "                                                                  batch_size=Batch_size,sort_key = lambda x: len(x.text),\n",
        "                                                                  sort_within_batch=True,\n",
        "                                                                  device=device)"
      ],
      "metadata": {
        "id": "yoYAIRwMDvN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "build the LSTM class"
      ],
      "metadata": {
        "id": "_lgOCCjxIgPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "       \n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "       \n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        \n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "                \n",
        "        \n",
        "            \n",
        "        return self.fc(hidden)\n",
        "\n"
      ],
      "metadata": {
        "id": "P8513HuOD0Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "set the hayper parameters and create LSTM instance"
      ],
      "metadata": {
        "id": "w9ZZMkfJIooN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim=len(Text.vocab)\n",
        "Embedding_dim =100\n",
        "Hidden_dim=256\n",
        "Output_dim =1\n",
        "N_layers=2\n",
        "Bidirectional = True\n",
        "Dropout = 0.5\n",
        "pad_IDX= Text.vocab.stoi[Text.pad_token]\n",
        "\n",
        "\n",
        "model = RNN(input_dim,Embedding_dim,Hidden_dim,Output_dim,N_layers,Bidirectional,Dropout,pad_IDX)"
      ],
      "metadata": {
        "id": "Tho4eWMQD5IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We retrieve the embeddings from the field's vocab, and check they're the correct size"
      ],
      "metadata": {
        "id": "aEqeVCAMJQe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_embeddings = Text.vocab.vectors\n",
        "print(pre_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05pPJG4lD5Lh",
        "outputId": "b2adb196-ca6c-4421-fbf5-e559bf7d638c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25002, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then replace the initial weights of the embedding layer with the pre-trained embeddings"
      ],
      "metadata": {
        "id": "P1f4CgSMJR7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.copy_(pre_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv9Nf9R8D5OR",
        "outputId": "89092420-3651-477a-ac2c-406dbb4e3472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.3669,  0.4154,  0.1348,  ...,  0.0244,  0.2211,  0.4317],\n",
              "        ...,\n",
              "        [-0.2222, -0.8740,  0.2754,  ..., -0.2819, -0.2160, -0.2122],\n",
              "        [ 1.2713,  0.6307,  0.4610,  ..., -0.9668,  1.5761, -1.0732],\n",
              "        [-0.9261,  0.5799, -1.9593,  ..., -0.6351, -0.1507,  0.9007]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize and token to all zeros to explicitly tell our model that, initially, they are irrelevant for determining sentiment."
      ],
      "metadata": {
        "id": "ILEhGtHDJW1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unk_idx = Text.vocab.stoi[Text.unk_token]\n",
        "model.embedding.weight.data[unk_idx]=torch.zeros(Embedding_dim)\n",
        "model.embedding.weight.data[pad_IDX]=torch.zeros(Embedding_dim)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb7IBYYKEIN3",
        "outputId": "b0658610-12a6-41fc-ed9a-62c0fe25fb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.3669,  0.4154,  0.1348,  ...,  0.0244,  0.2211,  0.4317],\n",
            "        ...,\n",
            "        [-0.2222, -0.8740,  0.2754,  ..., -0.2819, -0.2160, -0.2122],\n",
            "        [ 1.2713,  0.6307,  0.4610,  ..., -0.9668,  1.5761, -1.0732],\n",
            "        [-0.9261,  0.5799, -1.9593,  ..., -0.6351, -0.1507,  0.9007]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the optimizer and the criterion and place the model and criterion on the GPU"
      ],
      "metadata": {
        "id": "O2n_bFKLJbzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "66pbKgeOENca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "implement the function to calculate accuracy"
      ],
      "metadata": {
        "id": "wCF2PKjbJh9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds,y):\n",
        "  rounded_preds=torch.round(torch.sigmoid(preds))\n",
        "  correct = (rounded_preds==y).float()\n",
        "  acc = correct.sum()/len(correct)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "oEexoAOhENhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define the train function"
      ],
      "metadata": {
        "id": "FQ-6JLStJjaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,iterator,optimizer,criterion):\n",
        "  epoch_loss=0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text,text_lengths=batch.text\n",
        "    preds = model(text,text_lengths).squeeze(1)\n",
        "    loss = criterion(preds,batch.Sentiment)\n",
        "    acc = binary_accuracy(preds,batch.Sentiment)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss+= loss.item()\n",
        "    epoch_acc+= acc.item()\n",
        "\n",
        "  return   epoch_loss/len(iterator) , epoch_acc/len(iterator)"
      ],
      "metadata": {
        "id": "GpkYLABVENpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define the evaluation function"
      ],
      "metadata": {
        "id": "Aho8rnnUJshp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,iterator,criterion):\n",
        "  epoch_loss=0\n",
        "  epoch_acc=0\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      text,text_lengths= batch.text\n",
        "      preds = model(text,text_lengths).squeeze(1)\n",
        "      loss = criterion(preds,batch.Sentiment)\n",
        "      acc = binary_accuracy(preds,batch.Sentiment)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "  return    epoch_loss/len(iterator) , epoch_acc/len(iterator)\n"
      ],
      "metadata": {
        "id": "7rMR_VdCEZvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def epoch_time(start,end):\n",
        "  timeE = end - start\n",
        "  minutes = int(timeE/60)\n",
        "  secs = int(timeE-(minutes * 60))\n",
        "  return minutes , secs"
      ],
      "metadata": {
        "id": "JPZh8hu6EZxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training"
      ],
      "metadata": {
        "id": "iEkWQQwgJ25X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_epochs =10\n",
        "best_loss = float('inf')\n",
        "for epoch in range(N_epochs):\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss,valid_acc = evaluate(model,valid_iterator,criterion)\n",
        "\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  epoch_minutes ,epoch_seconds = epoch_time(start,end)\n",
        "\n",
        "\n",
        "  if valid_loss<best_loss:\n",
        "    best_loss = valid_loss\n",
        "    torch.save(model.state_dict(),'tut2-model.pt')\n",
        "  \n",
        "  print(f'epoch_no : {epoch+1:02} | Epoch Time: {epoch_minutes}m {epoch_seconds}s')\n",
        "  print(f'\\train_loss : {train_loss:.2f} | train_acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\valid_loss: {valid_loss:.2f} |  valid_acc: {valid_acc*100:.2f}%') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnGeDwCxEZ0G",
        "outputId": "f802cf8f-e623-48a0-dc24-ce5aae68a55e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch_no : 01 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.32 | train_acc: 86.21%\n",
            "\u000balid_loss: 0.41 |  valid_acc: 81.54%\n",
            "epoch_no : 02 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.31 | train_acc: 86.83%\n",
            "\u000balid_loss: 0.44 |  valid_acc: 81.65%\n",
            "epoch_no : 03 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.29 | train_acc: 87.41%\n",
            "\u000balid_loss: 0.43 |  valid_acc: 81.02%\n",
            "epoch_no : 04 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.28 | train_acc: 88.14%\n",
            "\u000balid_loss: 0.44 |  valid_acc: 81.46%\n",
            "epoch_no : 05 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.27 | train_acc: 88.68%\n",
            "\u000balid_loss: 0.46 |  valid_acc: 81.11%\n",
            "epoch_no : 06 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.25 | train_acc: 89.29%\n",
            "\u000balid_loss: 0.48 |  valid_acc: 80.93%\n",
            "epoch_no : 07 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.24 | train_acc: 89.79%\n",
            "\u000balid_loss: 0.52 |  valid_acc: 81.07%\n",
            "epoch_no : 08 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.23 | train_acc: 90.34%\n",
            "\u000balid_loss: 0.49 |  valid_acc: 80.69%\n",
            "epoch_no : 09 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.22 | train_acc: 90.71%\n",
            "\u000balid_loss: 0.52 |  valid_acc: 80.37%\n",
            "epoch_no : 10 | Epoch Time: 0m 9s\n",
            "\train_loss : 0.22 | train_acc: 91.06%\n",
            "\u000balid_loss: 0.53 |  valid_acc: 80.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test accuracy"
      ],
      "metadata": {
        "id": "bNf2kl7UJ9ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "test_loss,test_acc = evaluate(model,test_iterator,criterion)\n",
        "print(f'test_loss:{test_loss:.3f} | test_acc:{test_acc*100:3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5_e1fL2gpt_",
        "outputId": "ee2ca9a9-3540-47f8-9898-85b7bf62868b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss:0.412 | test_acc:81.743968%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing the user input"
      ],
      "metadata": {
        "id": "3kOrpzYbKE54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "def predict(model,sentence):\n",
        "  model.eval()\n",
        "  tokenized= [t.text for t in nlp.tokenizer(sentence)]\n",
        "  indexed = [Text.vocab.stoi[t] for t in tokenized]\n",
        "  length = [len(indexed)]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(1)\n",
        "  length_tensor = torch.LongTensor(length)\n",
        "  preds= torch.sigmoid(model(tensor,length_tensor))\n",
        "  return preds.item()\n"
      ],
      "metadata": {
        "id": "20KVQbDggqEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "positive tweet"
      ],
      "metadata": {
        "id": "kSwO8qVDKI3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model,\" almost appreciate everyone\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai-mCrjig3tH",
        "outputId": "7ba73498-d0d9-4955-9040-d5176fe5a99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8462774157524109"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "negative tweet"
      ],
      "metadata": {
        "id": "-Hf5lvgmKJmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model,\"paaain left chest heart gosh feel sick\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N3WRlZcg6MN",
        "outputId": "7ae0166a-ffba-4bff-f07e-865a583e3a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0036441341508179903"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}